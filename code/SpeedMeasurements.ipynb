{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    \"\"\"\n",
    "    This class loads and runs the tensorflow model\n",
    "    \"\"\"\n",
    "    def __init__(self, frozen_graph, gpu):\n",
    "        \"\"\"\n",
    "        frozen_graph: the path to the model\n",
    "        gpu: which gpu to use\n",
    "        \"\"\"\n",
    "        # load model into detection_graph\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n",
    "        detection_graph = tf.Graph()\n",
    "        with detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(frozen_graph, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "        self.graph = detection_graph\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth=True\n",
    "            self.sess = tf.Session(config=config)\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "            self.tensor_dict = {}\n",
    "            for key in ['detection_scores','detection_classes', 'detection_boxes']:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    self.tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n",
    "            self.image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "        \n",
    "    def timeit(self, images, number):\n",
    "        \"\"\"\n",
    "        images: one image resized to the correct size (e.g. 640x640)\n",
    "        number: how often the speedmeasurement should be done\n",
    "        \"\"\"\n",
    "        with self.graph.as_default():\n",
    "            # warmup\n",
    "            self.sess.run(self.tensor_dict, feed_dict={self.image_tensor: np.random.randint(0, 255, images.shape)})\n",
    "            return timeit.timeit(lambda: self.sess.run(self.tensor_dict, feed_dict={self.image_tensor: images}), number=number)/number*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('livedemo/d.jpg')\n",
    "img = cv2.resize(img[:, :img.shape[0], ::-1], (640, 640))\n",
    "imgs = cv2.resize(img, (300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.24ms\n",
      "12.44ms\n"
     ]
    }
   ],
   "source": [
    "#SSD\n",
    "p = Predictor('train/ssd_mobilenet_alex/1/frozen_inference_graph.pb', 0)\n",
    "print('%.2fms' % p.timeit(imgs[np.newaxis], 1))\n",
    "print('%.2fms' % p.timeit(imgs[np.newaxis], 10))\n",
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.32ms\n",
      "29.23ms\n"
     ]
    }
   ],
   "source": [
    "#SSD+FPN\n",
    "p = Predictor('train/ssd_julius_mobilefpn_large/frozen_inference_graph.pb', 0)\n",
    "print('%.2fms' % p.timeit(img[np.newaxis], 1))\n",
    "print('%.2fms' % p.timeit(img[np.newaxis], 10))\n",
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.69ms\n",
      "62.79ms\n"
     ]
    }
   ],
   "source": [
    "#RFCN\n",
    "p = Predictor('train/rfcn/9/frozen_inference_graph.pb', 0)\n",
    "print('%.2fms' % p.timeit(img[np.newaxis], 1))\n",
    "print('%.2fms' % p.timeit(img[np.newaxis], 10))\n",
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now with the test images\n",
    "data = np.load('val_data.npz')\n",
    "img = data['imgs']\n",
    "img = np.concatenate([cv2.resize(img[i], (640, 640))[np.newaxis] for i in range(len(img))])\n",
    "imgs = np.concatenate([cv2.resize(img[i], (300, 300))[np.newaxis] for i in range(len(img))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.89ms\n"
     ]
    }
   ],
   "source": [
    "#SSD\n",
    "p = Predictor('train/ssd_mobilenet_alex/1/frozen_inference_graph.pb', 0)\n",
    "print('%.2fms' % (p.timeit(imgs, 1) / len(imgs)))\n",
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.63ms\n"
     ]
    }
   ],
   "source": [
    "#SSD+FPN\n",
    "#batchsize of 85 seems to be to large\n",
    "p = Predictor('train/ssd_julius_mobilefpn_large/frozen_inference_graph.pb', 0)\n",
    "print('%.2fms' % (p.timeit(img, 1) / len(img)))\n",
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.94ms\n"
     ]
    }
   ],
   "source": [
    "#RFCN\n",
    "p = Predictor('train/rfcn/9/frozen_inference_graph.pb', 0)\n",
    "print('%.2fms' % (p.timeit(img, 1) / len(img)))\n",
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
