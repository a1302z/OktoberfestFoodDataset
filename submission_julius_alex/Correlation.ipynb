{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlate labeled data to checkout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime, timedelta, tzinfo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "#import matching as mt\n",
    "\n",
    "current_item = 'Bier'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read groundtruth - Merge categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = {}\n",
    "path = '/nfs/students/winter-term-2018/project_2/test/ids_to_name.csv'\n",
    "with open(path) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        label_names[row[1]] = row[2]\n",
    "df = pd.read_csv(path)\n",
    "df.head(len(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_categories = {}\n",
    "category_names = ['Bier', 'Bier Maß', 'Weißbier', 'Cola', 'Wasser', 'Curry-Wurst', 'Weißwein',\n",
    "                   'A-Schorle', 'Jägermeister', 'Pommes', 'Burger', 'Williamsbirne', 'Alm-Breze', 'Brotzeitkorb',\n",
    "                   'Käsespätzle']\n",
    "merged_categories['100'] = 0\n",
    "merged_categories['101'] = 1\n",
    "merged_categories['102'] = 0\n",
    "merged_categories['103'] = 1\n",
    "merged_categories['104'] = 0\n",
    "merged_categories['105'] = 1\n",
    "merged_categories['106'] = 2\n",
    "merged_categories['107'] = 1\n",
    "merged_categories['108'] = 2\n",
    "merged_categories['109'] = 1\n",
    "merged_categories['110'] = 2\n",
    "merged_categories['111'] = 1\n",
    "#merged_categories['112'] = None #Mass AFG\n",
    "merged_categories['113'] = 3\n",
    "merged_categories['114'] = 3\n",
    "merged_categories['115'] = 3\n",
    "merged_categories['116'] = 3\n",
    "merged_categories['117'] = 4\n",
    "merged_categories['118'] = 7\n",
    "#merged_categories['119'] = None #RedBull\n",
    "merged_categories['121'] = 4\n",
    "merged_categories['122'] = 4\n",
    "#merged_categories['123'] = None #Kaffee\n",
    "#merged_categories['124'] = None #Cappuccino\n",
    "#merged_categories['125'] = None #Secco Rose\n",
    "#merged_categories['126'] = None\n",
    "merged_categories['128'] = 4\n",
    "merged_categories['129'] = 6\n",
    "merged_categories['130'] = 6\n",
    "merged_categories['131'] = 6\n",
    "#merged_categories['132'] = None #lugana flasche\n",
    "#merged_categories['133'] = None #Grauer Burgunder\n",
    "merged_categories['134'] = 3\n",
    "merged_categories['173'] = 8\n",
    "merged_categories['197'] = 5\n",
    "merged_categories['204'] = 9\n",
    "merged_categories['206'] = 9\n",
    "merged_categories['207'] = 9\n",
    "merged_categories['196'] = 10\n",
    "merged_categories['171'] = 11\n",
    "merged_categories['201'] = 12\n",
    "merged_categories['199'] = 13\n",
    "merged_categories['205'] = 14\n",
    "\n",
    "\n",
    "for i in range(len(category_names)):\n",
    "    print(\"Merged in category %s (%d):\"%(category_names[i], i))\n",
    "    for key in merged_categories:\n",
    "        if merged_categories[key] == i:\n",
    "            print(\"\\t %s\"%label_names[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkout_logs = {}\n",
    "test_d = {}\n",
    "with open('/nfs/students/winter-term-2018/project_2/labels/schanzerAlmData.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(row)\n",
    "            line_count += 1\n",
    "        else:\n",
    "            if row[4] in merged_categories:\n",
    "                time = datetime.strptime(row[1]+' '+row[2], '%Y-%m-%d %H:%M:%S')\n",
    "                if time in checkout_logs:\n",
    "                    new_item = [int(merged_categories[row[4]]), float(row[3])]\n",
    "                    was_in_list = False\n",
    "                    for i in range(len(checkout_logs[time])):\n",
    "                        if new_item[0] == checkout_logs[time][i][0]:\n",
    "                            checkout_logs[time][i][1] += new_item[1]\n",
    "                            was_in_list = True\n",
    "                    if not was_in_list:\n",
    "                        checkout_logs[time].append(new_item)\n",
    "                else:\n",
    "                    checkout_logs[time] = [[int(merged_categories[row[4]]), float(row[3])]]\n",
    "                if merged_categories[row[4]] in test_d:\n",
    "                    test_d[merged_categories[row[4]]] += int(float(row[3]))\n",
    "                else:\n",
    "                    test_d[merged_categories[row[4]]] = int(float(row[3]))\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "#checkout_logs.sort(key=lambda first: first[0])\n",
    "#print(\"First checkout: %s\"%str(checkout_logs[0]))\n",
    "#print(\"Last checkout: %s\"%str(checkout_logs[-1]))\n",
    "print(test_d)\n",
    "#pprint.pprint(checkout_logs)\n",
    "\n",
    "def checkout_log_to_name(checkout_log):\n",
    "    data = checkout_logs[checkout_log]\n",
    "    s = ''\n",
    "    for d in data:\n",
    "        #print(d)\n",
    "        s += str(d[1])+'x '+str(category_names[d[0]])+' '\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(test_d.keys(), test_d.values(), width=1.0)\n",
    "plt.show()\n",
    "max_item = max(test_d, key=test_d.get)\n",
    "min_item = min(test_d, key=test_d.get)\n",
    "print(\"Most sold item was %s sold %s time(s) \"%(category_names[max_item], test_d[max_item]))\n",
    "print(\"Fewest sold item was %s sold %s time(s) \"%(category_names[min_item], test_d[min_item]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlate labeled data to checkouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_to_time(ts, tz=None):\n",
    "    #return datetime.utcfromtimestamp(int(ts))\n",
    "    return datetime.fromtimestamp(int(ts), tz=tz)\n",
    "print(ts_to_time('1526731043'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read labels from file\n",
    "\"\"\"\n",
    "label_file = open('/nfs/students/winter-term-2018/project_2/data_split/train/thumbnails/'+current_item+'/files.txt', mode='r').read()\n",
    "annotations = label_file.split('\\n')\n",
    "annotations.remove('')\n",
    "labeled_image_dict = {}\n",
    "image_data_dict = {}\n",
    "for a in annotations:\n",
    "    items = a.split(' ')\n",
    "    try:\n",
    "        if items[1] is '0':\n",
    "            continue\n",
    "    except:\n",
    "        print(items)\n",
    "        continue\n",
    "    labels = []\n",
    "    for i in range(int(items[1])):\n",
    "        labels.append(items[5*i+2:5*i+7])\n",
    "        labels[i][0] = int(labels[i][0])\n",
    "    time = ts_to_time(items[0][:10])\n",
    "    if time in labeled_image_dict:\n",
    "        if int(items[1]) > labeled_image_dict[time][0]:\n",
    "            print(\"Found label of timeframe with more labels:\\nOld: %s\\nNew: %s\"%(labeled_image_dict[time], (int(items[1]),labels)))    \n",
    "            labeled_image_dict[time] = (int(items[1]), labels)\n",
    "            image_data_dict[time] = plt.imread('/nfs/students/winter-term-2018/project_2/data_split/train/thumbnails/'+current_item+'/'+items[0])\n",
    "    else:\n",
    "        #add_time = timedelta(seconds=float(items[0][14:16])*6.0/90.0)\n",
    "        #print(add_time)\n",
    "        labeled_image_dict[time] = (int(items[1]), labels)\n",
    "        image_data_dict[time] = plt.imread('/nfs/students/winter-term-2018/project_2/data_split/train/thumbnails/'+current_item+'/'+items[0])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment for detailed checkout logs\n",
    "#pprint.pprint(checkout_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = annotations[0].split(' ')[0]\n",
    "print(test_img)\n",
    "test_date = ts_to_time(test_img[:10])\n",
    "print(test_date.astimezone())\n",
    "print(test_date)\n",
    "path = '/nfs/students/winter-term-2018/project_2/data_split/train/thumbnails/'+current_item+'/'+test_img\n",
    "img_data = plt.imread(path)\n",
    "if not img_data is None:\n",
    "    plt.imshow(img_data[:40,:330])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Matching problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First step: filter \n",
    "Remark: Very naively implemented (could use LSH filtering or stuff to make it faster)\n",
    "\"\"\"\n",
    "max_delta = timedelta(minutes=1)\n",
    "print(\"Maximal timedelta from checkout to image is %s\"%str(max_delta))\n",
    "count = 0\n",
    "count_nf = 0\n",
    "print_stuff = False\n",
    "filter_assignment = {}\n",
    "not_found_examples = []\n",
    "for image in labeled_image_dict:\n",
    "    found = False\n",
    "    for checkout in checkout_logs:\n",
    "        dif = abs(checkout - image)\n",
    "        if abs(dif.days) <= max_delta.days and dif < max_delta:#neccessary because of overflows\n",
    "            if print_stuff and count < 20:\n",
    "                print(\"Checkout: %s\\tImage: %s\\tDifference %s\"%(checkout, image, str(checkout-image)))\n",
    "            if image in filter_assignment:\n",
    "                filter_assignment[image].append(checkout)\n",
    "            else:\n",
    "                filter_assignment[image] = [checkout]\n",
    "            count += 1\n",
    "            found = True\n",
    "        i,c = image, checkout\n",
    "    if not found:\n",
    "        not_found_examples.append(image)\n",
    "        count_nf += 1\n",
    "        \n",
    "print(\"Did not found checkouts within delta t for %d/%d images\"%(count_nf, len(labeled_image_dict)))\n",
    "print(\"Found %d candidate pairs\"%count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity(image, checkout):\n",
    "    image_data = labeled_image_dict[image]\n",
    "    checkout_data = checkout_logs[checkout]\n",
    "    #print(image_data)\n",
    "    #print(checkout_data)\n",
    "    categories = {}\n",
    "    for obj in image_data[1]:\n",
    "        if obj[0] in categories:\n",
    "            categories[obj[0]] = [0.0, categories[obj[0]][1]+1.0]\n",
    "        else:\n",
    "            categories[obj[0]] = [0.0, 1.0]\n",
    "    for item in checkout_data:\n",
    "        if item[0] in categories:\n",
    "            categories[item[0]] = [item[1], categories[item[0]][1]]\n",
    "        else:\n",
    "            categories[item[0]] = [item[1], 0]\n",
    "    #print(categories)\n",
    "    score = 0.0\n",
    "    count = 0.0\n",
    "    for item, amt in categories.items():\n",
    "        score += max(amt)-abs(amt[0]-amt[1])#how many matching data points\n",
    "        count += max(amt)                   #how many data points in total\n",
    "    #print(\"Score = %f\\tCount = %f\"%(score, count))\n",
    "    score /= count\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_similarity(i, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Second step: evaluate simlilarity of candidate pairs\n",
    "i.e. is order and label identical (or at least similar)\n",
    "\"\"\"\n",
    "count = 0\n",
    "print_stuff = False\n",
    "time_difference_matches = []\n",
    "image_checkout_matches = []\n",
    "score_series = []\n",
    "threshold = 0.5\n",
    "for image, possible_matches in filter_assignment.items():\n",
    "    #pprint.pprint(\"Image %s has %d possible match(es) %s\"%(image,len(possible_matches), possible_matches))\n",
    "    ranking = []\n",
    "    best_sim_score = 0.0\n",
    "    best_match = None\n",
    "    for match in possible_matches:\n",
    "        sim_score = calc_similarity(image, match)\n",
    "        if sim_score > best_sim_score:\n",
    "            best_sim_score = sim_score\n",
    "            best_match = match\n",
    "        if sim_score > threshold:\n",
    "            ranking.append((match, sim_score))\n",
    "            #print(\"Image %s and checkout %s have score of %f\"%(labeled_image_dict[image], checkout_logs[match],sim_score))\n",
    "    if len(ranking) == 0:\n",
    "        count += 1\n",
    "        if print_stuff:\n",
    "            print(\"Could not match labels of %s to following checkouts:\"%str(labeled_image_dict[image]))\n",
    "            for m in possible_matches:\n",
    "                print(\"\\t%s\"%str(checkout_logs[m]))\n",
    "    else:\n",
    "        time_difference_matches.append(abs(image-best_match).total_seconds())\n",
    "        image_checkout_matches.append((image, best_match))\n",
    "    if print_stuff:\n",
    "        print(\"Best similarity score is %f\"%best_sim_score)\n",
    "    score_series.append(best_sim_score)\n",
    "print(\"No good correspondances for %d/%d images\"%(count, len(filter_assignment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series(time_difference_matches)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs = pd.Series(score_series)\n",
    "df_bs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, checkout in image_checkout_matches:\n",
    "    #print(\"Image %s matched to checkout %s\"%(img, checkout))\n",
    "    plt.imshow(image_data_dict[img])\n",
    "    plt.title(checkout_log_to_name(checkout))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Scatter plot of assignments</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p = []\n",
    "y_p = []\n",
    "day = 21\n",
    "min_h = 12\n",
    "max_h = 13\n",
    "for image in labeled_image_dict:\n",
    "    if image.day == day and image.hour > min_h and image.hour <= max_h:\n",
    "        x_p.append(image.timestamp())\n",
    "        y_p.append(1.0)\n",
    "for checkout in checkout_logs:\n",
    "    if checkout.day == day and checkout.hour > min_h and checkout.hour <= max_h:\n",
    "        x_p.append(checkout.timestamp())\n",
    "        y_p.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_p, y_p)\n",
    "for match in image_checkout_matches:\n",
    "    plt.arrow(match[0].timestamp(), 1.0, match[1].timestamp()-match[0].timestamp(), -1.0)\n",
    "plt.yticks([0.0,1.0],['Checkouts','Images'])\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in not_found_examples:\n",
    "    checkouts = []\n",
    "    x = []\n",
    "    td = timedelta(minutes=30)\n",
    "    for checkout in checkout_logs:\n",
    "        if abs(checkout-example) < td:\n",
    "            checkouts.append(checkout)\n",
    "            x.append(checkout.timestamp())\n",
    "    y = [0.0] * len(x)\n",
    "    x.append(example.timestamp())\n",
    "    y.append(1.0)\n",
    "    print(x)\n",
    "    print(y)\n",
    "    plt.scatter(x,y)\n",
    "    plt.arrow((example+timedelta(minutes=5)).timestamp(), 0.0, 0.0, 1.0)\n",
    "    plt.arrow((example-timedelta(minutes=5)).timestamp(), 0.0, 0.0, 1.0)\n",
    "    plt.arrow((example-timedelta(minutes=5)).timestamp(), 0.5, timedelta(minutes=10).total_seconds(), 0.0, label='10 minutes')\n",
    "    plt.text((example-timedelta(minutes=5)).timestamp(), 0.55, '10 minutes')\n",
    "    plt.yticks([0.0,1.0],['Checkouts','Images'])\n",
    "    plt.xticks([])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_found_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-tf",
   "language": "python",
   "name": "py-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
